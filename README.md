dedup
=====
*original written in about an hour on plane from SFO->EWR 7-23-15*

Scan directories and identify duplicate directories or files by hash with qualifying name or size threshold.

For speed large files only have the beginning and end hashed.

First cut, not much error checking, needs much work.


